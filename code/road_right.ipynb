{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T10:54:33.188948Z",
     "start_time": "2025-06-03T10:54:33.181226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### parameters\n",
    "place = 'tel_aviv'\n",
    "feature = 'road_right'"
   ],
   "id": "60b08391fa064320",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T10:54:36.977042Z",
     "start_time": "2025-06-03T10:54:33.188948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import zipfile\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.ops import unary_union, nearest_points\n",
    "from shapely.geometry import Point,Polygon,MultiPolygon\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "# Get the current working directory (e.g., the folder you're running from)\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import generic_filter\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "crs_prj = 'EPSG:2039'\n",
    "\n",
    "cwd = Path().resolve()\n",
    "# Get the parent directory\n",
    "parent_folder = f'{cwd.parent}/places/{place}'\n",
    "data_folder = f'{parent_folder}/shp'\n",
    "os.makedirs(f'{parent_folder}',exist_ok=True)\n",
    "os.makedirs(f'{parent_folder}/shp',exist_ok=True)\n",
    "os.makedirs(f'{parent_folder}/shp/{feature}',exist_ok=True)\n",
    "detail_folder = f'{data_folder}/{feature}'"
   ],
   "id": "a26072c94ebdfa9e",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T10:54:36.987761Z",
     "start_time": "2025-06-03T10:54:36.979054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Define paths\n",
    "input_dir = f'{detail_folder}/raw_data' # Directory containing zip files\n",
    "output_dir = f'{detail_folder}/unzip_raw_data'  # Directory to store outputs\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Temporary directory for unzipping\n",
    "temp_dir = os.path.join(output_dir, \"unzipped\")\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# Initialize list to hold filtered GeoDataFrames\n",
    "filtered_gdfs = []"
   ],
   "id": "5855c904a1f137a9",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T13:47:06.938094Z",
     "start_time": "2025-06-03T13:46:11.419144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_to_save = ['oidmigrash', 'msgush', 'msmigrash', 'idtaba', 'tyeudkarka', 'tyeudrashi', 'msshetach', 'geometry']\n",
    "\n",
    "# Unzip and process each shapefile\n",
    "for zip_path in glob(os.path.join(input_dir, \"*.zip\")):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        extract_path = os.path.join(temp_dir, os.path.splitext(os.path.basename(zip_path))[0])\n",
    "        zip_ref.extractall(extract_path)\n",
    "\n",
    "        for shp_path in glob(os.path.join(extract_path, \"**\", \"*.shp\"), recursive=True):\n",
    "            try:\n",
    "                gdf = gpd.read_file(shp_path)\n",
    "                if not gdf.empty:\n",
    "                    filtered_gdfs.append(gdf)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {shp_path}: {e}\")\n",
    "\n",
    "# Merge, filter, and save\n",
    "if filtered_gdfs:\n",
    "    merged_gdf = gpd.GeoDataFrame(pd.concat(filtered_gdfs, ignore_index=True), crs=filtered_gdfs[0].crs)\n",
    "    merged_gdf = merged_gdf[cols_to_save]\n",
    "\n",
    "    merged_gdf.to_file(os.path.join(output_dir, \"merged_gdf.shp\"))\n",
    "\n",
    "    # Filter for \"תחבורה\" in tyeudrashi\n",
    "    filtered = merged_gdf[merged_gdf[\"tyeudrashi\"] == \"תחבורה\"]\n",
    "    filtered.to_file(os.path.join(output_dir, \"tyeudrashi.shp\"))\n",
    "\n",
    "    # Remove duplicates by \"oidmigrash\"\n",
    "    filtered_unique = filtered.drop_duplicates(subset=\"oidmigrash\")\n",
    "    final_path = os.path.join(output_dir, \"merged_filtered_unique.shp\")\n",
    "    filtered_unique.to_file(final_path)\n",
    "\n",
    "    print(f\"✅ Final shapefile saved to: {final_path}\")\n",
    "else:\n",
    "    print(\"⚠️ No matching shapefiles found.\")\n"
   ],
   "id": "c1d225f7b666ff68",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T10:54:59.727988Z",
     "start_time": "2025-06-03T10:54:54.457390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Creating of perpendicular lines at specific positions along each street segment — typically at 1/3, 1/2, and 2/3 of the segment — on both the left and right sides.\n",
    "# \n",
    "# ✅ Purpose:\n",
    "# To sample the cross-section of the street at multiple representative points.\n",
    "# \n",
    "# These perpendiculars simulate measuring from the road center outward toward the edge (e.g., curb or parcel boundary).\n",
    "# Load your polygon layer\n",
    "gdf = filtered.copy()\n",
    "merged_geom = unary_union(gdf.geometry)\n",
    "# Split multipolygon into separate rows\n",
    "if isinstance(merged_geom, MultiPolygon):\n",
    "    geometries = list(merged_geom.geoms)\n",
    "else:\n",
    "    geometries = [merged_geom]\n",
    "\n",
    "# Create a new GeoDataFrame with each part as a separate row\n",
    "final_gdf = gpd.GeoDataFrame(geometry=geometries, crs=gdf.crs)\n",
    "final_gdf.to_file(f\"{detail_folder}/dissolved_cleaned.shp\")\n",
    "# Convert each polygon to its boundary (LineString or MultiLineString)\n",
    "gdf_polyline = final_gdf.copy()\n",
    "gdf_polyline[\"geometry\"] = gdf_polyline[\"geometry\"].boundary\n",
    "# # Optional: Save to file\n",
    "# gdf_polyline.to_file(f\"{detail_folder}/polygon_boundaries_as_lines.shp\")\n",
    "lines_gdf= gpd.read_file(f'{detail_folder}/side_lines_gdf0.shp')\n",
    "\n",
    "# Extract the start point of each line\n",
    "lines_gdf[\"start_point\"] = lines_gdf.geometry.apply(lambda geom: Point(geom.coords[0]))\n",
    "\n",
    "# Convert to GeoDataFrame of points for spatial join\n",
    "start_points_gdf = gpd.GeoDataFrame(lines_gdf.drop(columns=\"geometry\"), geometry=lines_gdf[\"start_point\"], crs=lines_gdf.crs)\n",
    "\n",
    "# Spatial join: find start points within road_right polygons\n",
    "joined = gpd.sjoin(start_points_gdf, final_gdf, how=\"inner\", predicate=\"within\")\n",
    "\n",
    "# Use index to filter original lines\n",
    "filtered_lines = lines_gdf.loc[joined.index]\n",
    "\n",
    "\n",
    "# Save result\n",
    "filtered_lines.drop(columns=[\"start_point\"]).to_file(f\"{detail_folder}/filtered_perpendicular_lines.shp\")"
   ],
   "id": "e19269f371ca958b",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T13:54:02.519205Z",
     "start_time": "2025-06-03T13:52:43.240703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  Computing the intersection of each perpendicular line with street boundary polylines (converted from polygons), and measuring the distance from the line’s start point to the closest intersection.\n",
    "# \n",
    "# ✅ Purpose:\n",
    "# To determine the distance from the center of the road to its edge on one side — this gives one half of the street width.\n",
    "# \n",
    "# If done for both left and right sides, you can calculate the full right-of-way width.\n",
    "\n",
    "# Build spatial index on street edge polylines\n",
    "edge_sindex = gdf_polyline.sindex\n",
    "\n",
    "# Prepare list to collect results\n",
    "results = []\n",
    "\n",
    "# Process each perpendicular line\n",
    "for idx, row in filtered_lines.iterrows():\n",
    "    line = row.geometry\n",
    "    start_point = row[\"start_point\"]\n",
    "\n",
    "    # Use spatial index to find candidate polylines near the line\n",
    "    candidate_idx = list(edge_sindex.intersection(line.bounds))\n",
    "    candidate_edges = gdf_polyline.iloc[candidate_idx]\n",
    "\n",
    "    # Compute intersections between the perpendicular line and candidate edges\n",
    "    intersections = []\n",
    "    for _, edge_row in candidate_edges.iterrows():\n",
    "        intersection = line.intersection(edge_row.geometry)\n",
    "        if not intersection.is_empty:\n",
    "            if intersection.geom_type == \"Point\":\n",
    "                intersections.append(intersection)\n",
    "            elif intersection.geom_type.startswith(\"Multi\"):\n",
    "                intersections.extend([\n",
    "                    geom for geom in intersection.geoms if geom.geom_type == \"Point\"\n",
    "                ])\n",
    "\n",
    "    # Keep the closest intersection point to the start of the line\n",
    "    if intersections:\n",
    "        nearest_point = min(intersections, key=lambda pt: start_point.distance(pt))\n",
    "        results.append({\n",
    "            **row.to_dict(),\n",
    "            \"intersection_point\": nearest_point,\n",
    "            \"width_side\": start_point.distance(nearest_point)\n",
    "        })\n",
    "\n",
    "# Create final GeoDataFrame with intersection points\n",
    "results_gdf = gpd.GeoDataFrame(results, geometry=\"intersection_point\", crs=crs_prj)\n",
    "\n",
    "# Optional: Save the result\n",
    "# results_gdf.to_file(f\"{detail_folder}/efficient_width_side_result.shp\")\n",
    "\n"
   ],
   "id": "8261538f8a0b25da",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T13:59:40.831218Z",
     "start_time": "2025-06-03T13:59:38.551855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Compute representative left, right, and total road widths for each street segment by aggregating perpendicular width measurements and merging them with street geometries.\n",
    "# Step 1: Merge perpendicular line results (width_side) into filtered_lines by 'oidrechov' and 'side'\n",
    "width_df = filtered_lines.merge(\n",
    "    results_gdf[['oidrechov', 'side', 'width_side']],\n",
    "    on=['oidrechov', 'side'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 2: Split 'side' into 'position' and 'onlyside' (e.g., 'start_left' → position='start', onlyside='left')\n",
    "width_df[['position', 'onlyside']] = width_df['side'].str.extract(r'(\\w+)_(\\w+)', expand=True)\n",
    "\n",
    "# Step 3: Load street geometries\n",
    "streets = gpd.read_file(f'{data_folder}/streets.shp')[['oidrechov', 'geometry']]\n",
    "\n",
    "# Step 4: Define function to calculate representative width\n",
    "def summarize_width(values):\n",
    "    values = [v for v in values if pd.notnull(v)]\n",
    "    if len(values) == 0:\n",
    "        return np.nan\n",
    "    elif len(values) == 1:\n",
    "        return values[0]\n",
    "    elif len(values) == 2:\n",
    "        return np.mean(values)\n",
    "    elif len(values) == 3:\n",
    "        pairs = [(values[i], values[j]) for i in range(3) for j in range(i + 1, 3)]\n",
    "        closest_pair = min(pairs, key=lambda pair: abs(pair[0] - pair[1]))\n",
    "        return np.mean(closest_pair)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Step 5: Group by street and side, and summarize width\n",
    "summary = width_df.groupby(['oidrechov', 'onlyside'])['width_side'].apply(summarize_width).unstack()\n",
    "\n",
    "# Step 6: Rename columns and calculate total width\n",
    "summary = summary.rename(columns={\"left\": \"left\", \"right\": \"right\"})\n",
    "summary[\"road_right\"] = summary[\"left\"] + summary[\"right\"]\n",
    "summary.reset_index(inplace=True)\n",
    "\n",
    "# Step 7: Merge width estimates into street geometries\n",
    "street_edges_gdf = streets.merge(summary, on='oidrechov', how='left')\n",
    "\n",
    "# Step 8: Save final output\n",
    "street_edges_gdf.to_file(f'{detail_folder}/{feature}.shp')\n"
   ],
   "id": "dae880df8958d25b",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "230235e5e3b78b3",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
