{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "# fields names\n",
    "ped_level = 'ped_level'\n",
    "general_path = f'{os.getcwd()}/ml'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_squared_error, mean_absolute_error,\n",
    "    explained_variance_score, median_absolute_error\n",
    ")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-11-08T10:04:01.743347Z",
     "start_time": "2025-11-08T10:03:54.440530Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T10:04:01.771282Z",
     "start_time": "2025-11-08T10:04:01.760603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_rfecv(X_train, y_train, X_test, y_test, max_depth,features_name):\n",
    "    if max_depth !='all':\n",
    "        selector = RFECV(\n",
    "            estimator=RandomForestRegressor(n_estimators=100, random_state=1, n_jobs=-1, max_depth=max_depth),\n",
    "            step=1,\n",
    "            cv=cv,\n",
    "            scoring='r2',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        start = time.time()\n",
    "        selector.fit(X_train, y_train)\n",
    "        print(f\"\\nFeature selection completed in {(time.time() - start):.2f} seconds\")\n",
    "\n",
    "        # Apply selected features\n",
    "        X_train_selected = selector.transform(X_train)\n",
    "        X_test_selected = selector.transform(X_test)\n",
    "\n",
    "        # Selected feature names\n",
    "        selected_features = [name for name, keep in zip(features_name, selector.support_) if keep]\n",
    "    else:\n",
    "        X_train_selected = X_train\n",
    "        X_test_selected = X_test\n",
    "\n",
    "\n",
    "    # ------------------------\n",
    "    # Train Final Regressor\n",
    "    # ------------------------\n",
    "\n",
    "    regressor = DecisionTreeRegressor(random_state=1)\n",
    "    regressor.fit(X_train_selected, y_train)\n",
    "\n",
    "    # ------------------------\n",
    "    # Evaluation\n",
    "    # ------------------------\n",
    "\n",
    "    y_pred = regressor.predict(X_test_selected)\n",
    "\n",
    "    print('\\nModel Performance:')\n",
    "    print('R² score:', r2_score(y_test, y_pred, multioutput='raw_values'))\n",
    "    print('Mean Squared Error:', mean_squared_error(y_test, y_pred, multioutput='raw_values'))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred, multioutput='raw_values'))\n",
    "    print('Explained Variance:', explained_variance_score(y_test, y_pred, multioutput='raw_values'))\n",
    "    print('Median Absolute Error:', median_absolute_error(y_test, y_pred, multioutput='raw_values'))\n",
    "\n",
    "    # ------------------------\n",
    "    # Grouped MSE by y_test\n",
    "    # ------------------------\n",
    "\n",
    "    stat_df = pd.DataFrame({'y_test': y_test, 'y_pred': y_pred})\n",
    "    group_mse = stat_df.groupby('y_test').apply(lambda df: mean_squared_error(df['y_test'], df['y_pred']))\n",
    "    print(\"\\nGroup-wise MSE:\")\n",
    "    print(group_mse)\n",
    "\n",
    "    # ------------------------\n",
    "    # Feature Importance (sorted)\n",
    "    # ------------------------\n",
    "    importances = regressor.feature_importances_\n",
    "    if max_depth =='all':\n",
    "        selected_features = features_name\n",
    "    sorted_features = sorted(zip(selected_features, importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(f\"\\n{len(selected_features)} Selected Features and Importances (sorted):\")\n",
    "    for name, imp in sorted_features:\n",
    "        print(f\"{name}: {imp:.4f}\")\n",
    "\n",
    "    # ------------------------\n",
    "    # Tree depth\n",
    "    # ------------------------\n",
    "\n",
    "    print(f\"\\nFinal Decision Tree Depth: {regressor.get_depth()}\")\n",
    "    return regressor, selected_features\n",
    "\n",
    "\n",
    "def create_node_df(regressor):\n",
    "    # Initialize list to store data\n",
    "    node_data = []\n",
    "\n",
    "    # Access tree\n",
    "    tree = regressor.tree_\n",
    "    node_count = tree.node_count\n",
    "\n",
    "    for node_id in range(node_count):\n",
    "        value = tree.value[node_id][0][0]  # average target value at node\n",
    "        impurity = tree.impurity[node_id]  # mean squared error\n",
    "        n_samples = tree.n_node_samples[node_id]  # number of samples\n",
    "\n",
    "        # Define group (1 if 0–1, 2 if 1–2, etc.)\n",
    "        group = round(value)  # since 0–1 → group 1, 1–2 → group 2, ...\n",
    "\n",
    "        # Check if this is a leaf node\n",
    "        is_leaf = (tree.children_left[node_id] == -1) and (tree.children_right[node_id] == -1)\n",
    "        leaf_id = node_id if is_leaf else -1  # -1 means not a leaf\n",
    "\n",
    "        # Collect\n",
    "        node_data.append({\n",
    "            'node_id': node_id,\n",
    "            'leaf_id': leaf_id,\n",
    "            'value': value,\n",
    "            'group': group,\n",
    "            'impurity': impurity,\n",
    "            'n_node_samples': n_samples\n",
    "        })\n",
    "\n",
    "    # Create DataFrame\n",
    "    return pd.DataFrame(node_data)\n",
    "\n",
    "\n",
    "def find_important_paths(regressor, node_df,total_samples,selected_features):\n",
    "    # Parameters\n",
    "\n",
    "    min_threshold = 0.0001\n",
    "    initial_threshold = 0.1\n",
    "    step = 0.0001\n",
    "\n",
    "    # Helper: get decision path to a node\n",
    "    def get_path_to_node(node_id):\n",
    "        path = []\n",
    "        i = node_id\n",
    "        while i != 0 and parent_nodes[i] is not None:\n",
    "            parent = parent_nodes[i]\n",
    "            feat_i = regressor.tree_.feature[parent]\n",
    "            feat = selected_features[feat_i]\n",
    "            threshold = regressor.tree_.threshold[parent]\n",
    "            direction = \"<=\" if i == regressor.tree_.children_left[parent] else \">\"\n",
    "            path.append(f\"{feat} {direction} {threshold:.6f}\")\n",
    "            i = parent\n",
    "        return \"--\".join(reversed(path))\n",
    "\n",
    "    # Make sure parent_nodes list is defined\n",
    "    parent_nodes = [None] * regressor.tree_.node_count\n",
    "    for i in range(regressor.tree_.node_count):\n",
    "        if regressor.tree_.children_left[i] != -1:\n",
    "            parent_nodes[regressor.tree_.children_left[i]] = i\n",
    "        if regressor.tree_.children_right[i] != -1:\n",
    "            parent_nodes[regressor.tree_.children_right[i]] = i\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Process each group\n",
    "    for group_id in sorted(node_df['group'].unique()):\n",
    "        group_nodes = node_df[node_df['group'] == group_id].sort_values(by='impurity')\n",
    "\n",
    "        threshold = initial_threshold\n",
    "        selected_nodes = pd.DataFrame()\n",
    "\n",
    "        while threshold >= min_threshold:\n",
    "            min_samples = total_samples * threshold\n",
    "            filtered = group_nodes[\n",
    "                (group_nodes['n_node_samples'] >= min_samples) &\n",
    "                (group_nodes['impurity'] < 1.0)\n",
    "            ]\n",
    "            selected_nodes = filtered.head(5)\n",
    "\n",
    "            if len(selected_nodes) >= 5:\n",
    "                break\n",
    "            else:\n",
    "                threshold -= step\n",
    "\n",
    "        # If valid nodes found, build full output\n",
    "        if not selected_nodes.empty:\n",
    "            selected_nodes = selected_nodes.copy()\n",
    "            selected_nodes['path'] = selected_nodes['node_id'].apply(get_path_to_node)\n",
    "            selected_nodes.to_csv(f\"{output_folder}/group_{group_id}.csv\", index=False)\n",
    "            print(f\"Group {group_id}: {len(selected_nodes)} nodes saved with threshold {threshold:.3%}\")\n",
    "        else:\n",
    "            print(f\"Group {group_id}: No nodes passed conditions.\")\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-08T10:04:01.792841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ------------------------\n",
    "# Load and Prepare Data\n",
    "# ------------------------\n",
    "\n",
    "ml_df = pd.read_csv(f'{general_path}/model_data_final_1.csv').drop(columns=['index_str_name', 'Unnamed: 0', 'length'])\n",
    "data_feature = ml_df.drop(columns=[ped_level])\n",
    "features_name = list(data_feature.columns)\n",
    "\n",
    "X = data_feature.to_numpy(dtype=np.float32)  # Use float32 for memory speed\n",
    "y = ml_df[ped_level].to_numpy(dtype=np.float32)\n",
    "\n",
    "# ------------------------\n",
    "# Split Data\n",
    "# ------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X ,y, test_size=0.2, random_state=1)\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=1)\n",
    "# ------------------------\n",
    "# Feature Selection with RFECV (Random Forest)\n",
    "# ------------------------\n",
    "# ------------------------\n",
    "# for max in ['all',5,10,20,None]:\n",
    "for max in [None]:\n",
    "    print(\"Training model with max_depth {}\".format(max) if max !='all' else \"Model with all features\")\n",
    "    regressor, selected_features = run_rfecv(X_train, y_train, X_test, y_test,max,features_name)\n",
    "     # Create output folder\n",
    "    output_folder = f\"{general_path}/group_nodes_{str(max)}\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    joblib.dump(regressor, f\"{output_folder}/decision_tree_{str(max)}.pkl\")\n",
    "    joblib.dump(selected_features, f\"{output_folder}/selected_features_{str(max)}.pkl\")\n",
    "    node_df = create_node_df(regressor)\n",
    "    total_samples = len(ml_df)\n",
    "    find_important_paths(regressor, node_df,total_samples,selected_features)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with max_depth None\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T14:22:22.723241Z",
     "start_time": "2025-11-06T14:22:22.716635Z"
    }
   },
   "cell_type": "code",
   "source": "str(None)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T13:20:15.738521Z",
     "start_time": "2025-11-06T13:20:08.615651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This code work with assumption that we already have tree\n",
    "\n",
    "# List of folder names\n",
    "ml_df = pd.read_csv(f'{general_path}/model_data_final_1.csv').drop(columns=['index_str_name', 'Unnamed: 0', 'length'])\n",
    "for max in [5,10,20,'all',None]:\n",
    "    output_folder = f\"{general_path}/group_nodes_{max}\"\n",
    "    regressor= joblib.load(f\"{output_folder}/decision_tree_{max}.pkl\")\n",
    "    selected_features =joblib.load(f\"{output_folder}/selected_features_{max}.pkl\")\n",
    "    node_df = create_node_df(regressor)\n",
    "    total_samples = len(ml_df)\n",
    "    find_important_paths(regressor, node_df,total_samples,selected_features)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0: 5 nodes saved with threshold 0.210%\n",
      "Group 1: 5 nodes saved with threshold 0.530%\n",
      "Group 2: 5 nodes saved with threshold 0.070%\n",
      "Group 3: 5 nodes saved with threshold 0.280%\n",
      "Group 4: 5 nodes saved with threshold 0.330%\n",
      "Group 0: 5 nodes saved with threshold 0.230%\n",
      "Group 1: 5 nodes saved with threshold 0.870%\n",
      "Group 2: 5 nodes saved with threshold 0.060%\n",
      "Group 3: 5 nodes saved with threshold 0.340%\n",
      "Group 4: 5 nodes saved with threshold 0.270%\n",
      "Group 0: 5 nodes saved with threshold 0.170%\n",
      "Group 1: 5 nodes saved with threshold 0.440%\n",
      "Group 2: 5 nodes saved with threshold 0.060%\n",
      "Group 3: 5 nodes saved with threshold 0.250%\n",
      "Group 4: 5 nodes saved with threshold 0.260%\n",
      "Group 0: 5 nodes saved with threshold 0.210%\n",
      "Group 1: 5 nodes saved with threshold 0.530%\n",
      "Group 2: 5 nodes saved with threshold 0.070%\n",
      "Group 3: 5 nodes saved with threshold 0.280%\n",
      "Group 4: 5 nodes saved with threshold 0.330%\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\achit\\\\OneDrive - ariel.ac.il\\\\Current_research\\\\ASC2\\\\pythonProject\\\\places\\\\tel_aviv/ml/group_nodes_None/selected_features_None.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      6\u001B[39m output_folder = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgeneral_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/group_nodes_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mmax\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m      7\u001B[39m regressor= joblib.load(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutput_folder\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/decision_tree_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mmax\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.pkl\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m selected_features =\u001B[43mjoblib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43moutput_folder\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m/selected_features_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m.pkl\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m node_df = create_node_df(regressor)\n\u001B[32m     10\u001B[39m total_samples = \u001B[38;5;28mlen\u001B[39m(ml_df)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\numpy_pickle.py:735\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(filename, mmap_mode, ensure_native_byte_order)\u001B[39m\n\u001B[32m    733\u001B[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001B[32m    734\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m735\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m    736\u001B[39m         \u001B[38;5;28;01mwith\u001B[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001B[38;5;28;01mas\u001B[39;00m (\n\u001B[32m    737\u001B[39m             fobj,\n\u001B[32m    738\u001B[39m             validated_mmap_mode,\n\u001B[32m    739\u001B[39m         ):\n\u001B[32m    740\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(fobj, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    741\u001B[39m                 \u001B[38;5;66;03m# if the returned file object is a string, this means we\u001B[39;00m\n\u001B[32m    742\u001B[39m                 \u001B[38;5;66;03m# try to load a pickle file generated with an version of\u001B[39;00m\n\u001B[32m    743\u001B[39m                 \u001B[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001B[39;00m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\achit\\\\OneDrive - ariel.ac.il\\\\Current_research\\\\ASC2\\\\pythonProject\\\\places\\\\tel_aviv/ml/group_nodes_None/selected_features_None.pkl'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T13:49:11.678380Z",
     "start_time": "2025-11-06T13:49:11.670747Z"
    }
   },
   "cell_type": "code",
   "source": "selected_features",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['day part',\n",
       " 'season',\n",
       " 'day',\n",
       " 'buildings',\n",
       " 'businesses',\n",
       " 'educationa',\n",
       " 'Health_ser',\n",
       " 'Leisure_am',\n",
       " 'Playground',\n",
       " 'Sport_faci',\n",
       " 'synagogues',\n",
       " 'bus_statio',\n",
       " 'lighting',\n",
       " 'bike_trail',\n",
       " 'parks',\n",
       " 'SEleve1_10',\n",
       " 'closeness',\n",
       " 'betweennes',\n",
       " 'highway',\n",
       " 'bench',\n",
       " 'green_canopy',\n",
       " 'pop_dens',\n",
       " 'road_right',\n",
       " 'shadows',\n",
       " 'sidewalk_width',\n",
       " 'slope']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
